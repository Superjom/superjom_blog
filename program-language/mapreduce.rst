MapReduce: Simplified Data Processing on Large Clusters 笔记
==============================================================
.. sectionauthor:: Superjom <yanchunwei {AT} outlook.com>

*2014-12-25*

.. note::
    
    最近在做分布式参数服务器，从头开始把相关框架的原理看看。
    Google的MapReduce应该是当前主流的Hadoop这类应用的原点吧，看了之后，真的有一些基础的借鉴作用。
    框架本身很简洁实用，不拖泥带水，看完之后浮想联翩。

编程模型
-------------
框架内的计算就是计算 `key/value` pair集合，然后产生一个对应的输出pair集合。

基本的操作就是两个：

1. **Map** 由框架的用户自定义，处理一个输入pair，并产生一个或多个输出pair中间产物。 框架会将具有相同key的pair汇总在一块，传输给Reduce函数处理。
2. **Reduce** 也由用户定义，接收一个key，以及对应的一到多个value，使用用户定义的操作将这些value汇总起来。 最终得到一个更小的输出集合。

具体实现
---------
MapReduce 是一种编程框架，具体的实现可以根据不同的场景来设计。

比如，一个小型的共享内存的框架，或者一个大型的集群。

论文里提到的MapReduce的集群用的就是最普通的PC搭载Linux，双核，2G内存。
用这样的机器来构建集群，并处理大型任务，需要框架具有很高的容错和并发能力。

论文里提到的应用场景及对框架的要求如下：

1. 机器配置很普通，易发生故障，需要框架实现高容错性
2. 集群内联网络连接速度一般，需要尽量降低数据传输（除了任务起始和结束，Map，Reduce过程中间不需要传输数据）
3. 一个集群往往有成百上千台机器，需要框架提供非常好的并发执行能力
4. 存储是集群内部的分布式存储，考虑到单个节点的故障率，需要框架冗余存储，提供透明的可靠存储
5. 一个集群可能同时有多个用户提交的任务在执行，需要框架提供好的调度能力

执行过程
----------
**Map** 操作通过将输入数据拆分到多台机器上，并用多台机器同时处理数据，来实行分布式并行。

**Reduce** 类似地，会通过用户定义的拆分函数来将中间的key拆分到多台机器上，并行处理。

具体的执行过程如下：

1. MapReduce 先将输入文件拆分成 M块，每块的大小从16MB到64MB都可以。
之后，系统会在集群里启动多个程序的副本并行执行。
2. 其中一个程序的拷贝比较特殊— Master. 
其余的节点都称为Worker，所有Worker的任务均由Master指定。
全局会有M个map任务和R个reduce任务需要指定。 
Master会调度空闲的节点来执行Map或者Reduce任务。
3. Map任务中，程序会读取给定的输入文件，然后拆分成key/value，
并用对应的Map程序对key/value就行处理。
产生的中间key/value会在内存中缓存。
4. 内存中缓存的中间key/value会周期性地写到磁盘，
并顺便用Reduce的拆分函数拆成R份。
磁盘中的文件路径会发送给Master，Master之后会将路径转发给进行Reduce任务的Worker作为输入数据的路径。
5. 当执行Reduce的Worker知道了输入数据的路径(s)之后，
它会通过远程调用来读取自己的输入数据，
读取完毕，会根据key来就行排序，将有相同key的数据排在一起。
如果数据巨大（内存无法容纳），那么可以用外排进行排序。
6. Reduce Worker将排完序的key/value数据从前往后扫描一次，
用用户定义的Reduce函数进行处理，并将产物输出到文件中。
7. 当所有的map和reduce任务都完成了，用户程序返回。

当用户的MapReduce任务成功运行完毕，最终会输出R个输出文件。
这R个文件一般没有必要合并成一个文件（而且有可能数据巨大）。
也可以直接作为另外一轮MapReduce任务的输入。

容错
-------------------------
MapReduce一般都用来处理巨量的数据，
集群的规模也会达到成百上千的机器。 
所以，框架本事必须能够容纳机器故障。

Worker Failure
****************
Master周期性地Ping每个Worker节点。
如果在指定的时间间隔里没有回音，Master就会将此Worker标定为失效。
此Worker完成或者正在执行的任何map/reduce任务的状态都会被重置。 
Master会将此任务调度给其他Worker重新处理。

其中，失效Workder上已经完成的任务还需要重新执行，
是因为输出数据在磁盘上，失效了就无法读取。

如果失效Worker A的任务被后来调度的Worker B完成。
失效Worker A上输出文件路径如果被告知了Reduce节点，
如果Reduce Worker还没有读取A上的数据，那之后会直接告知B的输出路径，并读取B上的数据。

MapReduce框架是能够应付大规模集群故障的，因为所需要的容错仅仅是重启任务而已。   
